{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6044d56f",
   "metadata": {},
   "source": [
    "# Lichen Likelihood Project: Expectation Maximization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "33cb1520",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cd5f9173",
   "metadata": {},
   "outputs": [],
   "source": [
    "unpickled_df = pd.read_pickle('element_analysis.pkl') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2eeb8158",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Nitrogen (% dw)_binned', 'Sulfur (% dw)_binned',\n",
       "       'Phosphorous (ppm dw)_binned', 'Lead (ppm dw)_binned',\n",
       "       'Copper (ppm dw)_binned', 'Chromium (ppm dw)_binned',\n",
       "       'Year of tissue collection_binned', 'Air pollution score_binned',\n",
       "       'Region_binned',\n",
       "       'Code for scientific name and authority in lookup table_binned'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print columns ending in \"binned\"\n",
    "unpickled_df.columns[unpickled_df.columns.str.endswith('binned')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a631ef49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helpers\n",
    "df = unpickled_df.copy()\n",
    "def idx_map_from_series(s):\n",
    "    \"\"\"Return dict mapping original category -> index and reverse list\"\"\"\n",
    "    cats = list(pd.Categorical(s).categories)\n",
    "    mapping = {c:i for i,c in enumerate(cats)}\n",
    "    return mapping, cats\n",
    "\n",
    "def one_hot_index_from_value(mapping, val):\n",
    "    return mapping[val]\n",
    "\n",
    "def normalize_rows(mat, axis=-1):\n",
    "    s = mat.sum(axis=axis, keepdims=True)\n",
    "    s[s == 0] = 1.0\n",
    "    return mat / s\n",
    "\n",
    "def logsumexp(a, axis=None):\n",
    "    a_max = np.max(a, axis=axis, keepdims=True)\n",
    "    res = a_max + np.log(np.sum(np.exp(a - a_max), axis=axis, keepdims=True))\n",
    "    if axis is not None:\n",
    "        return np.squeeze(res, axis=axis)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bb62ab3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class BayesianNetworkEM:\n",
    "    def __init__(self, hidden_states=2, pollution_latent=True, seed=0):\n",
    "        \"\"\"\n",
    "        Initializes CPT tables with random values consistent with the BN structure.\n",
    "        \"\"\"\n",
    "        np.random.seed(seed)\n",
    "        self.df = df.copy().reset_index(drop=True)\n",
    "        self.N = len(df)\n",
    "        self.H = hidden_states # need at least 2 latent classes \n",
    "        self.pollution_latent = pollution_latent # if pollution is hidden ig\n",
    "        self.elements = [\n",
    "            'Nitrogen (% dw)_binned',\n",
    "            'Sulfur (% dw)_binned',\n",
    "            'Phosphorous (ppm dw)_binned',\n",
    "            'Lead (ppm dw)_binned',\n",
    "            'Copper (ppm dw)_binned',\n",
    "            'Chromium (ppm dw)_binned'\n",
    "        ]\n",
    "        self.year_col = 'Year of tissue collection_binned'\n",
    "        self.pollution_col = 'Air pollution score_binned'\n",
    "        self.region_col = 'Region_binned'\n",
    "        self.species_col = 'Code for scientific name and authority in lookup table_binned'\n",
    "        self.maps = {}\n",
    "        self.rev = {}\n",
    "        cols_for_map = self.elements + [self.year_col, self.pollution_col, self.region_col, self.species_col]\n",
    "        for col in cols_for_map:\n",
    "            mapping, cats = idx_map_from_series(self.df[col])\n",
    "            self.maps[col] = mapping\n",
    "            self.rev[col] = cats\n",
    "        self.K_region = len(self.rev[self.region_col])\n",
    "        self.K_year = len(self.rev[self.year_col])\n",
    "        self.K_poll = len(self.rev[self.pollution_col])\n",
    "        self.K_species = len(self.rev[self.species_col])\n",
    "        self.K_elem = {col: len(self.rev[col]) for col in self.elements}\n",
    "\n",
    "        # Initialize CPTs as probabilities, not log probs\n",
    "        self.initialize_random_CPTs()\n",
    "\n",
    "    def initialize_random_CPTs(self):\n",
    "            \"\"\"\n",
    "            Randomly initialize all CPTs:\n",
    "            Ensure each CPT is normalized over its conditional domain.\n",
    "            \"\"\"\n",
    "            # P(H | Region, Year)\n",
    "            self.P_H_given_RY = np.random.rand(self.K_region, self.K_year, self.H)\n",
    "            self.P_H_given_RY = normalize_rows(self.P_H_given_RY, axis=-1)\n",
    "            # P(Pe | H)\n",
    "            self.P_Pe_given_H = np.random.rand(self.H, self.K_poll)\n",
    "            self.P_Pe_given_H = normalize_rows(self.P_Pe_given_H, axis=-1)\n",
    "            # P(Sp | H, Pe)\n",
    "            self.P_Sp_given_HP = np.random.rand(self.H, self.K_poll, self.K_species)\n",
    "            self.P_Sp_given_HP = normalize_rows(self.P_Sp_given_HP, axis=-1)\n",
    "            # For each element: P(Elem | Sp, Pe)\n",
    "            self.P_elem_given_SP = {}\n",
    "            for col in self.elements:\n",
    "                self.P_elem_given_SP[col] = np.random.rand(self.K_species, self.K_poll, self.K_elem[col])\n",
    "                self.P_elem_given_SP[col] = normalize_rows(self.P_elem_given_SP[col], axis=-1)\n",
    "\n",
    "    def e_step(self):\n",
    "        \"\"\"\n",
    "        Performs the E-step\n",
    "            For each sample n:\n",
    "                Compute posterior responsibilities\n",
    "            Store in self.gamma with shape [num_samples, num_hidden_states]\n",
    "        \"\"\"\n",
    "\n",
    "\n",
    "    def compute_posterior_hidden_probs(self, sample_row):\n",
    "        \"\"\"\n",
    "        Compute P(H=h | observed sample features) for a single sample\n",
    "        Returns a vector normalized over hidden states\n",
    "        \"\"\"\n",
    "\n",
    "\n",
    "    def m_step(self):\n",
    "        \"\"\"\n",
    "        Performs the M-step:\n",
    "            Update CPTs:\n",
    "                - P(H | Region, FieldDate)\n",
    "                - P(Pollution | H)\n",
    "                - P(Species | H, Pollution)\n",
    "                - P(Element_i_bucket | Species, Pollution) for each element node\n",
    "        Uses expected counts\n",
    "        \"\"\"\n",
    "\n",
    "\n",
    "    def update_hidden_CPT(self):\n",
    "        \"\"\"\n",
    "        Update P(H | Region, FieldDate)\n",
    "        Accumulate weighted counts per condition using responsibilities calculated above\n",
    "        \"\"\"\n",
    "\n",
    "\n",
    "    def update_pollution_CPT(self):\n",
    "        \"\"\"\n",
    "        Update P(Pollution | H)\n",
    "        Pollution is observed, responsibilities provides the weighting.\n",
    "        \"\"\"\n",
    "\n",
    "\n",
    "    def update_species_CPT(self):\n",
    "        \"\"\"\n",
    "        Update: P(Species | H, Pollution)\n",
    "        Species is observed, conditioned on hidden state and pollution bucket(S)\n",
    "        \"\"\"\n",
    "\n",
    "\n",
    "    def update_element_bucket_CPTs(self):\n",
    "        \"\"\"\n",
    "        For each tissue element bucket node:\n",
    "            Update: P(ElementBucket | Species, Pollution)\n",
    "        Summed over hidden responsibilities since element buckets have no H parent\n",
    "        \"\"\"\n",
    "\n",
    "\n",
    "    def log_likelihood(self):\n",
    "        \"\"\"\n",
    "        Compute the complete-data log likelihood using current CPTs and responsibilities\n",
    "        Used for eval\n",
    "        \"\"\"\n",
    "\n",
    "\n",
    "    def run(self, max_iters=50, tol=1e-6):\n",
    "        \"\"\"\n",
    "        Full EM loop:\n",
    "        initialize_random_CPTs()\n",
    "        e_step()\n",
    "        m_step()\n",
    "        compute log likelihood and check tolerance\n",
    "        Repeat.\n",
    "        Returns learned CPT parameters.\n",
    "        \"\"\"\n",
    "    def predict_pollution_distribution(self, row):\n",
    "        \"\"\"\n",
    "        Compute P(Pollution | observed row)\n",
    "        using:\n",
    "            P(P | H) * P(H | row)\n",
    "\n",
    "        return numpy array of num_pollution_values\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b3ceca82",
   "metadata": {},
   "outputs": [],
   "source": [
    "bnem= BayesianNetworkEM(hidden_states=2, pollution_latent=False, seed=42)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
