{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6044d56f",
   "metadata": {},
   "source": [
    "# Lichen Likelihood Project: Expectation Maximization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "33cb1520",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib import pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "cd5f9173",
   "metadata": {},
   "outputs": [],
   "source": [
    "unpickled_df = pd.read_pickle('element_analysis.pkl') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "2eeb8158",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Nitrogen (% dw)_binned', 'Sulfur (% dw)_binned',\n",
       "       'Phosphorous (ppm dw)_binned', 'Lead (ppm dw)_binned',\n",
       "       'Copper (ppm dw)_binned', 'Chromium (ppm dw)_binned',\n",
       "       'Year of tissue collection_binned', 'Air pollution score_binned',\n",
       "       'Region_binned',\n",
       "       'Code for scientific name and authority in lookup table_binned'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print columns ending in \"binned\"\n",
    "unpickled_df.columns[unpickled_df.columns.str.endswith('binned')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "518bddc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Region_binned\n",
       "6     6860\n",
       "10     318\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unpickled_df[\"Region_binned\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "a631ef49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helpers\n",
    "df = unpickled_df.copy()\n",
    "def idx_map_from_series(s):\n",
    "    \"\"\"Return dict mapping original category\"\"\"\n",
    "    cats = list(pd.Categorical(s).categories)\n",
    "    mapping = {c:i for i,c in enumerate(cats)}\n",
    "    return mapping, cats\n",
    "\n",
    "def one_hot_index_from_value(mapping, val):\n",
    "    return mapping[val]\n",
    "\n",
    "def normalize_rows(mat, axis=-1, alpha=1e-2):\n",
    "    \"\"\"\n",
    "    Normalize\n",
    "    \"\"\"\n",
    "    arr = mat.astype(float).copy()\n",
    "    arr += float(alpha)\n",
    "    s = arr.sum(axis=axis, keepdims=True)\n",
    "    s[s == 0] = 1.0\n",
    "    return arr / s\n",
    "\n",
    "def logsumexp(a, axis=None): # self explanatory\n",
    "    a_max = np.max(a, axis=axis, keepdims=True)\n",
    "    res = a_max + np.log(np.sum(np.exp(a - a_max), axis=axis, keepdims=True))\n",
    "    if axis is not None:\n",
    "        return np.squeeze(res, axis=axis)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "bb62ab3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPS = 1e-10\n",
    "class BayesianNetworkEM:\n",
    "    def __init__(self, df, hidden_states=2, seed=0):\n",
    "        \"\"\"\n",
    "        Initializes CPT tables with random values consistent with the BN structure.\n",
    "        \"\"\"\n",
    "        np.random.seed(seed)\n",
    "        self.df = df.copy().reset_index(drop=True)\n",
    "        self.N = len(self.df)\n",
    "        self.H = hidden_states\n",
    "        # element node column names\n",
    "        self.elements = [\n",
    "            'Nitrogen (% dw)_binned',\n",
    "            'Sulfur (% dw)_binned',\n",
    "            'Phosphorous (ppm dw)_binned',\n",
    "            'Lead (ppm dw)_binned',\n",
    "            'Copper (ppm dw)_binned',\n",
    "            'Chromium (ppm dw)_binned'\n",
    "        ]\n",
    "        self.year_col = 'Year of tissue collection_binned'\n",
    "        self.pollution_col = 'Air pollution score_binned'\n",
    "        self.region_col = 'Region_binned'\n",
    "        self.species_col = 'Code for scientific name and authority in lookup table_binned'\n",
    "        self.maps = {}\n",
    "        self.rev = {}\n",
    "        cols_for_map = self.elements + [self.year_col, self.pollution_col, self.region_col, self.species_col]\n",
    "        for col in cols_for_map:\n",
    "            mapping, cats = idx_map_from_series(self.df[col])\n",
    "            self.maps[col] = mapping\n",
    "            self.rev[col] = cats\n",
    "\n",
    "        self.K_region = len(self.rev[self.region_col])\n",
    "        self.K_year = len(self.rev[self.year_col])\n",
    "        self.K_poll = len(self.rev[self.pollution_col])\n",
    "        self.K_species = len(self.rev[self.species_col])\n",
    "        self.K_elem = {col: len(self.rev[col]) for col in self.elements}\n",
    "        self.initialize_random_CPTs()\n",
    "        self.gamma = np.zeros((self.N, self.H))\n",
    "\n",
    "    def initialize_random_CPTs(self):\n",
    "        \"\"\"\n",
    "        Randomly initialize all CPTs:\n",
    "        Ensure each CPT is normalized over its conditional domain.\n",
    "        \"\"\"\n",
    "        self.P_H_given_RY = normalize_rows(np.random.rand(self.K_region, self.K_year, self.H), axis=2)\n",
    "\n",
    "        self.P_Pe_given_H = normalize_rows(np.random.rand(self.H, self.K_poll), axis=1)\n",
    "\n",
    "        # model P(Sp | H, Pe)\n",
    "        self.P_Sp_given_HPe = normalize_rows(\n",
    "            np.random.rand(self.H, self.K_poll, self.K_species), axis=2\n",
    "        )\n",
    "\n",
    "        # elements depend on (Pe, Sp)\n",
    "        self.P_elem = {}\n",
    "        for col in self.elements:\n",
    "            arr = np.random.rand(self.K_poll, self.K_species, self.K_elem[col])\n",
    "            self.P_elem[col] = normalize_rows(arr, axis=2)\n",
    "\n",
    "    def e_step(self):\n",
    "        \"\"\"\n",
    "        Performs the E-step\n",
    "            For each sample n:\n",
    "                Compute posterior responsibilities\n",
    "            Store in self.gamma with shape [num_samples, num_hidden_states]\n",
    "        \"\"\"\n",
    "        idx_region = self.df[self.region_col].map(self.maps[self.region_col]).values\n",
    "        idx_year = self.df[self.year_col].map(self.maps[self.year_col]).values\n",
    "        idx_species = self.df[self.species_col].map(self.maps[self.species_col]).values\n",
    "        idx_poll = self.df[self.pollution_col].map(self.maps[self.pollution_col]).values\n",
    "        self.P_region = np.bincount(idx_region) / self.N\n",
    "        self.P_year   = np.bincount(idx_year) / self.N\n",
    "        N = self.N\n",
    "        H = self.H\n",
    "        Kp = self.K_poll\n",
    "\n",
    "        for i in range(N):\n",
    "            r = idx_region[i]\n",
    "            y = idx_year[i]\n",
    "            sp = idx_species[i]\n",
    "            p_val = idx_poll[i]\n",
    "            # log P(H | r,y)\n",
    "            log_ph = np.log(self.P_H_given_RY[r, y, :] + EPS)\n",
    "            # log P(Pe | H)\n",
    "            log_ppe = np.log(self.P_Pe_given_H[:, p_val] + EPS)\n",
    "            # log P(Sp | H, Pe)\n",
    "            log_psp = np.log(self.P_Sp_given_HPe[:, p_val, sp] + EPS)\n",
    "            # elements are d seperated from H when Pe and Sp are observed\n",
    "            log_unnorm = log_ph + log_ppe + log_psp\n",
    "            log_denom = logsumexp(log_unnorm, axis=0)\n",
    "            self.gamma[i, :] = np.exp(log_unnorm - log_denom)\n",
    "\n",
    "        return self.gamma\n",
    "\n",
    "    def compute_posterior_hidden_probs(self, sample_row):\n",
    "        \"\"\"\n",
    "        Compute P(H=h | observed sample features) for a single sample\n",
    "        Returns a vector normalized over hidden states\n",
    "        \"\"\"\n",
    "        r = self.maps[self.region_col][sample_row[self.region_col]]\n",
    "        y = self.maps[self.year_col][sample_row[self.year_col]]\n",
    "        s = self.maps[self.species_col][sample_row[self.species_col]]\n",
    "\n",
    "        log_ph = np.log(self.P_H_given_RY[r, y, :] + EPS)\n",
    "        if self.pollution_col in sample_row.index and pd.notna(sample_row[self.pollution_col]):\n",
    "            p_obs = self.maps[self.pollution_col][sample_row[self.pollution_col]]\n",
    "            log_ppe = np.log(self.P_Pe_given_H[:, p_obs] + EPS)\n",
    "            # include Sp | Pe\n",
    "            log_psp_obs = np.log(self.P_Sp_given_HPe[:, p_obs, s] + EPS)\n",
    "            log_unnorm = log_ph + log_ppe + log_psp_obs\n",
    "            log_norm = logsumexp(log_unnorm, axis=0)\n",
    "            return np.exp(log_unnorm - log_norm)\n",
    "\n",
    "        # log_contrib_pe[h] = log P(Pe=pe | H=h) + log P(Sp=s | H,Pe=pe) + sum_k log P(elem_k | pe, s) forall (updates pe)\n",
    "        Kp = self.K_poll\n",
    "        log_contrib = np.zeros((Kp, self.H)) \n",
    "        elem_vals = {}\n",
    "        for col in self.elements:\n",
    "            elem_vals[col] = self.maps[col][sample_row[col]]\n",
    "        for pe in range(Kp):\n",
    "            # log P(Pe=pe | H)\n",
    "            logppe = np.log(self.P_Pe_given_H[:, pe] + EPS)\n",
    "            # log P(Sp = s | H, Pe=pe)\n",
    "            log_psp_pe = np.log(self.P_Sp_given_HPe[:, pe, s] + EPS)\n",
    "            # sum over log P(elem | pe, s)\n",
    "            log_elems = 0.0\n",
    "            for col in self.elements:\n",
    "                log_elems += np.log(self.P_elem[col][pe, s, elem_vals[col]] + EPS)\n",
    "            # log contribution per h\n",
    "            log_contrib[pe, :] = logppe + log_psp_pe + log_elems\n",
    "\n",
    "        # log_p_h = log_ph + logsum_pe [ logppe + log_psp_pe + log_elems ] (update for each hidden)\n",
    "        log_sum_pe_per_h = logsumexp(log_contrib, axis=0)\n",
    "        log_p_h = log_ph + log_sum_pe_per_h\n",
    "        log_norm = logsumexp(log_p_h, axis=0)\n",
    "        return np.exp(log_p_h - log_norm)\n",
    "\n",
    "    def m_step(self):\n",
    "        \"\"\"\n",
    "        Performs the M-step:\n",
    "            Update CPTs:\n",
    "                - P(H | Region, FieldDate)\n",
    "                - P(Pollution | H)\n",
    "                - P(Species | H, Pollution)\n",
    "                - P(Element_i_bucket | Species, Pollution) for each element node\n",
    "        Uses expected counts\n",
    "        \"\"\"\n",
    "        # precompute indices\n",
    "        idx_region = self.df[self.region_col].map(self.maps[self.region_col]).values\n",
    "        idx_year = self.df[self.year_col].map(self.maps[self.year_col]).values\n",
    "        idx_species = self.df[self.species_col].map(self.maps[self.species_col]).values\n",
    "        idx_poll = self.df[self.pollution_col].map(self.maps[self.pollution_col]).values\n",
    "        N = self.N\n",
    "        H = self.H\n",
    "        Kp = self.K_poll\n",
    "\n",
    "        #P(H | Region, Year) counts\n",
    "        counts_H_RY = np.zeros((self.K_region, self.K_year, H))\n",
    "        for i in range(N):\n",
    "            r = idx_region[i]; y = idx_year[i]\n",
    "            counts_H_RY[r, y, :] += self.gamma[i, :] \n",
    "        self.P_H_given_RY = normalize_rows(counts_H_RY, axis=2)\n",
    "        # P(Pe | H)\n",
    "        counts_Pe_H = np.zeros((H, Kp))\n",
    "        for i in range(N):\n",
    "            p = idx_poll[i]\n",
    "            counts_Pe_H[:, p] += self.gamma[i, :]\n",
    "        # counts_Pe_H \n",
    "        self.P_Pe_given_H = normalize_rows(counts_Pe_H, axis=1)\n",
    "        # P(Sp | H, Pe)\n",
    "        counts_Sp_HPe = np.zeros((H, Kp, self.K_species))\n",
    "        for i in range(N):\n",
    "            p = idx_poll[i]\n",
    "            s = idx_species[i]\n",
    "            counts_Sp_HPe[:, p, s] += self.gamma[i, :]\n",
    "        # normalize over species\n",
    "        self.P_Sp_given_HPe = normalize_rows(counts_Sp_HPe, axis=2)\n",
    "\n",
    "        # 4) P(elem | Pe, Sp) doesnt need gamma bc dsep\n",
    "        for col in self.elements:\n",
    "            Kval = self.K_elem[col]\n",
    "            counts_elem = np.zeros((Kp, self.K_species, Kval))\n",
    "            for i in range(N):\n",
    "                p = idx_poll[i]\n",
    "                s = idx_species[i]\n",
    "                val = self.maps[col][self.df[col].iloc[i]]\n",
    "                counts_elem[p, s, val] += 1.0\n",
    "            self.P_elem[col] = normalize_rows(counts_elem, axis=2)\n",
    "\n",
    "    def update_hidden_CPT(self):\n",
    "        \"\"\"\n",
    "        Update P(H | Region, FieldDate)\n",
    "        Accumulate weighted counts per condition using responsibilities calculated above\n",
    "        \"\"\"\n",
    "        # identical to part of m_step\n",
    "        counts_H_RY = np.zeros((self.K_region, self.K_year, self.H))\n",
    "        idx_region = self.df[self.region_col].map(self.maps[self.region_col]).values\n",
    "        idx_year = self.df[self.year_col].map(self.maps[self.year_col]).values\n",
    "        for i in range(self.N):\n",
    "            r = idx_region[i]; y = idx_year[i]\n",
    "            counts_H_RY[r, y, :] += self.gamma[i, :]\n",
    "        self.P_H_given_RY = normalize_rows(counts_H_RY, axis=2)\n",
    "\n",
    "    def update_pollution_CPT(self):\n",
    "        \"\"\"\n",
    "        Update P(Pollution | H)\n",
    "        Pollution is observed, responsibilities provides the weighting.\n",
    "        \"\"\"\n",
    "        counts_Pe_H = np.zeros((self.H, self.K_poll))\n",
    "        idxPoll = self.df[self.pollution_col].map(self.maps[self.pollution_col]).values\n",
    "        for i in range(self.N):\n",
    "            p = idxPoll[i]\n",
    "            counts_Pe_H[:, p] += self.gamma[i, :]\n",
    "        self.P_Pe_given_H = normalize_rows(counts_Pe_H, axis=1)\n",
    "\n",
    "    def update_species_CPT(self):\n",
    "        \"\"\"\n",
    "        Update: P(Species | H, Pollution)\n",
    "        Species is observed, conditioned on hidden state and pollution bucket(S)\n",
    "        \"\"\"\n",
    "        counts_Sp_HPe = np.zeros((self.H, self.K_poll, self.K_species))\n",
    "        idx_species = self.df[self.species_col].map(self.maps[self.species_col]).values\n",
    "        idx_poll = self.df[self.pollution_col].map(self.maps[self.pollution_col]).values\n",
    "        for i in range(self.N):\n",
    "            p = idx_poll[i]\n",
    "            s = idx_species[i]\n",
    "            counts_Sp_HPe[:, p, s] += self.gamma[i, :]\n",
    "        self.P_Sp_given_HPe = normalize_rows(counts_Sp_HPe, axis=2)\n",
    "\n",
    "    def update_element_bucket_CPTs(self):\n",
    "        \"\"\"\n",
    "        For each tissue element bucket node:\n",
    "            Update: P(ElementBucket | Species, Pollution)\n",
    "        Summed over hidden responsibilities since element buckets have no H parent\n",
    "        \"\"\"\n",
    "        idx_species = self.df[self.species_col].map(self.maps[self.species_col]).values\n",
    "        idx_poll = self.df[self.pollution_col].map(self.maps[self.pollution_col]).values\n",
    "        N = self.N\n",
    "        Kp = self.K_poll\n",
    "        for col in self.elements:\n",
    "            counts_elem = np.zeros((Kp, self.K_species, self.K_elem[col]))\n",
    "            for i in range(N):\n",
    "                p = idx_poll[i]\n",
    "                s = idx_species[i]\n",
    "                val = self.maps[col][self.df[col].iloc[i]]\n",
    "                counts_elem[p, s, val] += 1.0\n",
    "            self.P_elem[col] = normalize_rows(counts_elem, axis=2)\n",
    "\n",
    "    def log_likelihood(self):\n",
    "        \"\"\"\n",
    "        Observed-data log-likelihood:\n",
    "        sum_i log P(observed_i) = sum_i log sum_h P(H|r,y) P(Pe|H) P(Sp|H) prod_k P(elem_k | Pe, Sp)\n",
    "        If Pe is missing for some rows (not expected in training) we marginalize over Pe as well.\n",
    "        \"\"\"\n",
    "        idx_region = self.df[self.region_col].map(self.maps[self.region_col]).values\n",
    "        idx_year = self.df[self.year_col].map(self.maps[self.year_col]).values\n",
    "        idx_species = self.df[self.species_col].map(self.maps[self.species_col]).values\n",
    "        idx_poll = self.df[self.pollution_col].map(self.maps[self.pollution_col]).values\n",
    "\n",
    "        total = 0.0\n",
    "        for i in range(self.N):\n",
    "            r = idx_region[i]; y = idx_year[i]; s = idx_species[i]\n",
    "            # compute log evidence per h (if Pe observed)\n",
    "            p_obs = idx_poll[i]\n",
    "            log_ph = np.log(self.P_H_given_RY[r, y, :] + EPS)  # (H,)\n",
    "            # sum element log-likelihood (depends on pe)\n",
    "            if pd.notna(self.df[self.pollution_col].iloc[i]):\n",
    "                # Pe observed\n",
    "                log_ppe = np.log(self.P_Pe_given_H[:, p_obs] + EPS)\n",
    "                log_psp = np.log(self.P_Sp_given_HPe[:, p_obs, s] + EPS)\n",
    "                # element contributions (same for all h)\n",
    "                log_elems = 0.0\n",
    "                for col in self.elements:\n",
    "                    val = self.maps[col][self.df[col].iloc[i]]\n",
    "                    log_elems += np.log(self.P_elem[col][p_obs, s, val] + EPS)\n",
    "                log_u = log_ph +log_ppe + log_psp + log_elems\n",
    "                total += float(logsumexp(log_u, axis=0))\n",
    "            else:\n",
    "                # Pe missing\n",
    "                pass\n",
    "                # compute log_ppe[h,pe] + log_elem(pe) foreach var\n",
    "                Kp = self.K_poll\n",
    "                log_contrib = np.zeros((Kp, self.H))\n",
    "                elem_vals = {col: self.maps[col][self.df[col].iloc[i]] for col in self.elements}\n",
    "                for pe in range(Kp):\n",
    "                    logppe = np.log(self.P_Pe_given_H[:, pe] + EPS)\n",
    "                    log_elems = 0.0\n",
    "                    for col in self.elements:\n",
    "                        log_elems += np.log(self.P_elem[col][pe, s, elem_vals[col]] + EPS)\n",
    "                    log_contrib[pe, :] = logppe + log_elems\n",
    "                # for each h: log_p_h = log_ph + logsumexp_over_pe(log_contrib[:,h])\n",
    "                log_sum_pe_per_h = logsumexp(log_contrib, axis=0)\n",
    "                log_u_h = log_ph + log_sum_pe_per_h\n",
    "                total += float(logsumexp(log_u_h, axis=0))\n",
    "        return total\n",
    "\n",
    "    def run(self, max_iters=100, tol=1e-6, verbose=True):\n",
    "        \"\"\"\n",
    "        Full EM loop:\n",
    "        initialize_random_CPTs()\n",
    "        e_step()\n",
    "        m_step()\n",
    "        compute log likelihood and check tolerance\n",
    "        Repeat.\n",
    "        Returns learned CPT parameters.\n",
    "        \"\"\"\n",
    "        lls= []\n",
    "        prev_ll = -np.inf\n",
    "        for it in range(1, max_iters+1):\n",
    "            self.e_step()\n",
    "            self.m_step()\n",
    "            ll = self.log_likelihood()\n",
    "            lls.append(ll)\n",
    "            if verbose:\n",
    "                print(f\"Iter {it:3d}  ll = {ll:.6f}\")\n",
    "            if np.isfinite(prev_ll) and abs(ll - prev_ll) < tol:\n",
    "                if verbose:\n",
    "                    print(\"Converged (tol).\")\n",
    "                break\n",
    "            prev_ll = ll\n",
    "        plt.figure(figsize=(8,5))\n",
    "        plt.plot(lls, marker='o')\n",
    "        plt.title(\"EM Training Log-Likelihood\")\n",
    "        plt.xlabel(\"Iteration\")\n",
    "        plt.ylabel(\"Log-Likelihood\")\n",
    "        plt.grid(True)\n",
    "        os.makedirs(\"plots\", exist_ok=True)\n",
    "        save_path = \"plots/log_likelihood_curve.png\"\n",
    "        plt.savefig(save_path, dpi=300, bbox_inches=\"tight\")\n",
    "        plt.close()\n",
    "\n",
    "        return {\n",
    "            'P_H_given_RY': self.P_H_given_RY,\n",
    "            'P_Pe_given_H': self.P_Pe_given_H,\n",
    "            'P_Sp_given_H': self.P_Sp_given_HPe,\n",
    "            'P_elem': self.P_elem\n",
    "        }\n",
    "\n",
    "    def predict_pollution_distribution(self, row):\n",
    "        \"\"\"\n",
    "        Compute P(Pollution | observed row)\n",
    "        Uses:\n",
    "            P(Pe | row) = sum_h P(Pe | H=h) * P(H=h | row)\n",
    "        \"\"\"\n",
    "        # compute posterior P(H | row)\n",
    "        p_h = self.compute_posterior_hidden_probs(row)\n",
    "        p_pe = (p_h[:, None] * self.P_Pe_given_H).sum(axis=0)\n",
    "        p_pe = p_pe / (p_pe.sum() + EPS)\n",
    "        return p_pe\n",
    "    def compute_global_hidden_prior(self):\n",
    "        \"\"\"\n",
    "        Compute prior P(H) using dataset\n",
    "        \"\"\"\n",
    "        idx_region = self.df[self.region_col].map(self.maps[self.region_col]).values\n",
    "        idx_year   = self.df[self.year_col].map(self.maps[self.year_col]).values\n",
    "        counts_RF = np.zeros((self.K_region, self.K_year))\n",
    "        for i in range(self.N):\n",
    "            counts_RF[idx_region[i], idx_year[i]] += 1\n",
    "        p_RF = counts_RF / counts_RF.sum()\n",
    "\n",
    "        # prior on H=sum_{R,F} P(H|R,F) * P(R,F)\n",
    "        P_H = (self.P_H_given_RY * p_RF[...,None]).sum(axis=(0,1))\n",
    "        P_H = P_H / P_H.sum()\n",
    "        return P_H\n",
    "    def predict_pollution_from_elem_species(self, row, P_H=None):\n",
    "        \"\"\"\n",
    "        Compute P(Pe | Tissue data, Species)\n",
    "        \"\"\"\n",
    "        if P_H is None:\n",
    "            P_H = self.compute_global_hidden_prior()\n",
    "        sp = self.maps[self.species_col][row[self.species_col]]\n",
    "        # marginalize Pe, want it without region/field col. date\n",
    "        Kp = self.K_poll\n",
    "        scores = np.zeros(Kp)\n",
    "        for pe in range(Kp):\n",
    "            log_ps = np.log(self.P_Pe_given_H[:, pe] + EPS)\n",
    "            log_el = 0.0\n",
    "            for col in self.elements:\n",
    "                val = self.maps[col][row[col]]\n",
    "                log_el += np.log(self.P_elem[col][pe, sp, val] + EPS)\n",
    "            x = np.log(P_H + EPS) + log_ps\n",
    "            ls = logsumexp(x, axis=0)\n",
    "            # P(Pe=pe, elems,sp) = sum_h P(H=h)*P(Pe|H=h)*P(elem|pe,sp)\n",
    "            scores[pe] = ls + log_el\n",
    "        scores = np.exp(scores - logsumexp(scores))\n",
    "        return scores\n",
    "    def print_CPTs(self, precision=4):\n",
    "        \"\"\"\n",
    "        Print all CPTs with actual category labels instead of numeric indices.\n",
    "        Structured so mapping to LaTeX tables is easy.\n",
    "        \"\"\"\n",
    "\n",
    "        def fmt_prob(p):\n",
    "            return f\"{p:.{precision}f}\"\n",
    "        print(\"\\n P(Region) \")\n",
    "        for r in range(self.K_region):\n",
    "            name = self.rev[self.region_col][r]\n",
    "            print(f\"{name}: {self.P_region[r]:.{precision}f}\")\n",
    "\n",
    "        # Prior P(Year)\n",
    "        print(\"\\n P(Year) \")\n",
    "        for y in range(self.K_year):\n",
    "            name = self.rev[self.year_col][y]\n",
    "            print(f\"{name}: {self.P_year[y]:.{precision}f}\")\n",
    "        # P(H | Region, Year)\n",
    "        print(\"\\n CPT: P(H | Region, Year)\")    \n",
    "        for r_idx, r in enumerate(self.rev[self.region_col]):\n",
    "            for y_idx, y in enumerate(self.rev[self.year_col]):\n",
    "                row = self.P_H_given_RY[r_idx, y_idx]\n",
    "                probs = \"  \".join([f\"H={h}: {fmt_prob(row[h])}\" for h in range(self.H)])\n",
    "                print(f\"Region={r:20s}  Year={y:20s}  ->  {probs}\")\n",
    "\n",
    "        #  P(Pollution | H) \n",
    "        print(\"\\n CPT: P(Pollution | H) \")\n",
    "        for h in range(self.H):\n",
    "            row = self.P_Pe_given_H[h]\n",
    "            for p_idx, p in enumerate(self.rev[self.pollution_col]):\n",
    "                print(f\"H={h}  Pollution={p:25s}  ->  {fmt_prob(row[p_idx])}\")\n",
    "            print()\n",
    "\n",
    "        #  P(Species | H, Pollution) \n",
    "        print(\"\\n CPT: P(Species | H, Pollution) \")\n",
    "        for h in range(self.H):\n",
    "            for p_idx, p in enumerate(self.rev[self.pollution_col]):\n",
    "                row = self.P_Sp_given_HPe[h, p_idx]\n",
    "                probs = \"  \".join(\n",
    "                    f\"{self.rev[self.species_col][s_idx]}: {fmt_prob(row[s_idx])}\"\n",
    "                    for s_idx in range(self.K_species)\n",
    "                )\n",
    "                print(f\"H={h}  Pollution={p:25s}  ->  {probs}\")\n",
    "            print()\n",
    "\n",
    "        #  P(Element | Pollution, Species) \n",
    "        for col in self.elements:\n",
    "            print(f\"\\n CPT: P({col} | Pollution, Species) \")\n",
    "            for p_idx, p in enumerate(self.rev[self.pollution_col]):\n",
    "                for s_idx, s in enumerate(self.rev[self.species_col]):\n",
    "                    row = self.P_elem[col][p_idx, s_idx]\n",
    "                    probs = \"  \".join(\n",
    "                        f\"{self.rev[col][e_idx]}: {fmt_prob(row[e_idx])}\"\n",
    "                        for e_idx in range(self.K_elem[col])\n",
    "                    )\n",
    "                    print(f\"Pollution={p:25s}  Species={s:25s}  ->  {probs}\")\n",
    "                print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "b3ceca82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter   1  ll = -45155.837438\n",
      "Iter   2  ll = -45114.606336\n",
      "Iter   3  ll = -45101.784938\n",
      "Iter   4  ll = -45095.777810\n",
      "Iter   5  ll = -45091.430278\n",
      "Iter   6  ll = -45087.350140\n",
      "Iter   7  ll = -45083.176200\n",
      "Iter   8  ll = -45078.846012\n",
      "Iter   9  ll = -45074.370626\n",
      "Iter  10  ll = -45069.762442\n",
      "Iter  11  ll = -45065.027561\n",
      "Iter  12  ll = -45060.182063\n",
      "Iter  13  ll = -45055.265722\n",
      "Iter  14  ll = -45050.344138\n",
      "Iter  15  ll = -45045.500704\n",
      "Iter  16  ll = -45040.822670\n",
      "Iter  17  ll = -45036.386428\n",
      "Iter  18  ll = -45032.246837\n",
      "Iter  19  ll = -45028.433153\n",
      "Iter  20  ll = -45024.951045\n",
      "Iter  21  ll = -45021.788143\n",
      "Iter  22  ll = -45018.920453\n",
      "Iter  23  ll = -45016.317915\n",
      "Iter  24  ll = -45013.948448\n",
      "Iter  25  ll = -45011.780539\n",
      "Iter  26  ll = -45009.784699\n",
      "Iter  27  ll = -45007.934152\n",
      "Iter  28  ll = -45006.205059\n",
      "Iter  29  ll = -45004.576470\n",
      "Iter  30  ll = -45003.030147\n",
      "Iter  31  ll = -45001.550330\n",
      "Iter  32  ll = -45000.123491\n",
      "Iter  33  ll = -44998.738087\n",
      "Iter  34  ll = -44997.384346\n",
      "Iter  35  ll = -44996.054056\n",
      "Iter  36  ll = -44994.740389\n",
      "Iter  37  ll = -44993.437726\n",
      "Iter  38  ll = -44992.141515\n",
      "Iter  39  ll = -44990.848127\n",
      "Iter  40  ll = -44989.554734\n",
      "Iter  41  ll = -44988.259194\n",
      "Iter  42  ll = -44986.959947\n",
      "Iter  43  ll = -44985.655924\n",
      "Iter  44  ll = -44984.346465\n",
      "Iter  45  ll = -44983.031250\n",
      "Iter  46  ll = -44981.710238\n",
      "Iter  47  ll = -44980.383619\n",
      "Iter  48  ll = -44979.051777\n",
      "Iter  49  ll = -44977.715257\n",
      "Iter  50  ll = -44976.374740\n",
      "Iter  51  ll = -44975.031028\n",
      "Iter  52  ll = -44973.685020\n",
      "Iter  53  ll = -44972.337704\n",
      "Iter  54  ll = -44970.990133\n",
      "Iter  55  ll = -44969.643415\n",
      "Iter  56  ll = -44968.298689\n",
      "Iter  57  ll = -44966.957105\n",
      "Iter  58  ll = -44965.619796\n",
      "Iter  59  ll = -44964.287861\n",
      "Iter  60  ll = -44962.962335\n",
      "Iter  61  ll = -44961.644168\n",
      "Iter  62  ll = -44960.334204\n",
      "Iter  63  ll = -44959.033169\n",
      "Iter  64  ll = -44957.741652\n",
      "Iter  65  ll = -44956.460105\n",
      "Iter  66  ll = -44955.188840\n",
      "Iter  67  ll = -44953.928030\n",
      "Iter  68  ll = -44952.677719\n",
      "Iter  69  ll = -44951.437831\n",
      "Iter  70  ll = -44950.208187\n",
      "Iter  71  ll = -44948.988515\n",
      "Iter  72  ll = -44947.778468\n",
      "Iter  73  ll = -44946.577641\n",
      "Iter  74  ll = -44945.385582\n",
      "Iter  75  ll = -44944.201811\n",
      "Iter  76  ll = -44943.025828\n",
      "Iter  77  ll = -44941.857128\n",
      "Iter  78  ll = -44940.695212\n",
      "Iter  79  ll = -44939.539592\n",
      "Iter  80  ll = -44938.389805\n",
      "Iter  81  ll = -44937.245422\n",
      "Iter  82  ll = -44936.106052\n",
      "Iter  83  ll = -44934.971357\n",
      "Iter  84  ll = -44933.841060\n",
      "Iter  85  ll = -44932.714952\n",
      "Iter  86  ll = -44931.592912\n",
      "Iter  87  ll = -44930.474911\n",
      "Iter  88  ll = -44929.361033\n",
      "Iter  89  ll = -44928.251484\n",
      "Iter  90  ll = -44927.146609\n",
      "Iter  91  ll = -44926.046907\n",
      "Iter  92  ll = -44924.953039\n",
      "Iter  93  ll = -44923.865845\n",
      "Iter  94  ll = -44922.786348\n",
      "Iter  95  ll = -44921.715761\n",
      "Iter  96  ll = -44920.655485\n",
      "Iter  97  ll = -44919.607105\n",
      "Iter  98  ll = -44918.572379\n",
      "Iter  99  ll = -44917.553220\n",
      "Iter 100  ll = -44916.551673\n",
      "Iter 101  ll = -44915.569886\n",
      "Iter 102  ll = -44914.610070\n",
      "Iter 103  ll = -44913.674466\n",
      "Iter 104  ll = -44912.765296\n",
      "Iter 105  ll = -44911.884717\n",
      "Iter 106  ll = -44911.034778\n",
      "Iter 107  ll = -44910.217371\n",
      "Iter 108  ll = -44909.434190\n",
      "Iter 109  ll = -44908.686693\n",
      "Iter 110  ll = -44907.976072\n",
      "Iter 111  ll = -44907.303227\n",
      "Iter 112  ll = -44906.668752\n",
      "Iter 113  ll = -44906.072925\n",
      "Iter 114  ll = -44905.515712\n",
      "Iter 115  ll = -44904.996777\n",
      "Iter 116  ll = -44904.515495\n",
      "Iter 117  ll = -44904.070981\n",
      "Iter 118  ll = -44903.662109\n",
      "Iter 119  ll = -44903.287553\n",
      "Iter 120  ll = -44902.945813\n",
      "Iter 121  ll = -44902.635253\n",
      "Iter 122  ll = -44902.354133\n",
      "Iter 123  ll = -44902.100642\n",
      "Iter 124  ll = -44901.872928\n",
      "Iter 125  ll = -44901.669129\n",
      "Iter 126  ll = -44901.487393\n",
      "Iter 127  ll = -44901.325906\n",
      "Iter 128  ll = -44901.182906\n",
      "Iter 129  ll = -44901.056699\n",
      "Iter 130  ll = -44900.945675\n",
      "Iter 131  ll = -44900.848311\n",
      "Iter 132  ll = -44900.763185\n",
      "Iter 133  ll = -44900.688972\n",
      "Iter 134  ll = -44900.624453\n",
      "Iter 135  ll = -44900.568508\n",
      "Iter 136  ll = -44900.520118\n",
      "Iter 137  ll = -44900.478362\n",
      "Iter 138  ll = -44900.442409\n",
      "Iter 139  ll = -44900.411517\n",
      "Iter 140  ll = -44900.385025\n",
      "Iter 141  ll = -44900.362344\n",
      "Iter 142  ll = -44900.342959\n",
      "Iter 143  ll = -44900.326413\n",
      "Iter 144  ll = -44900.312309\n",
      "Iter 145  ll = -44900.300299\n",
      "Iter 146  ll = -44900.290083\n",
      "Iter 147  ll = -44900.281397\n",
      "Iter 148  ll = -44900.274016\n",
      "Iter 149  ll = -44900.267747\n",
      "Iter 150  ll = -44900.262421\n",
      "Iter 151  ll = -44900.257895\n",
      "Iter 152  ll = -44900.254047\n",
      "Iter 153  ll = -44900.250773\n",
      "Iter 154  ll = -44900.247982\n",
      "Iter 155  ll = -44900.245601\n",
      "Iter 156  ll = -44900.243563\n",
      "Iter 157  ll = -44900.241815\n",
      "Iter 158  ll = -44900.240310\n",
      "Iter 159  ll = -44900.239010\n",
      "Iter 160  ll = -44900.237881\n",
      "Iter 161  ll = -44900.236895\n",
      "Iter 162  ll = -44900.236030\n",
      "Iter 163  ll = -44900.235265\n",
      "Iter 164  ll = -44900.234583\n",
      "Iter 165  ll = -44900.233971\n",
      "Iter 166  ll = -44900.233418\n",
      "Iter 167  ll = -44900.232912\n",
      "Iter 168  ll = -44900.232446\n",
      "Iter 169  ll = -44900.232012\n",
      "Iter 170  ll = -44900.231606\n",
      "Iter 171  ll = -44900.231221\n",
      "Iter 172  ll = -44900.230854\n",
      "Iter 173  ll = -44900.230502\n",
      "Iter 174  ll = -44900.230161\n",
      "Iter 175  ll = -44900.229829\n",
      "Iter 176  ll = -44900.229505\n",
      "Iter 177  ll = -44900.229185\n",
      "Iter 178  ll = -44900.228870\n",
      "Iter 179  ll = -44900.228557\n",
      "Iter 180  ll = -44900.228246\n",
      "Iter 181  ll = -44900.227935\n",
      "Iter 182  ll = -44900.227625\n",
      "Iter 183  ll = -44900.227314\n",
      "Iter 184  ll = -44900.227003\n",
      "Iter 185  ll = -44900.226690\n",
      "Iter 186  ll = -44900.226375\n",
      "Iter 187  ll = -44900.226058\n",
      "Iter 188  ll = -44900.225739\n",
      "Iter 189  ll = -44900.225417\n",
      "Iter 190  ll = -44900.225093\n",
      "Iter 191  ll = -44900.224766\n",
      "Iter 192  ll = -44900.224435\n",
      "Iter 193  ll = -44900.224102\n",
      "Iter 194  ll = -44900.223765\n",
      "Iter 195  ll = -44900.223426\n",
      "Iter 196  ll = -44900.223083\n",
      "Iter 197  ll = -44900.222736\n",
      "Iter 198  ll = -44900.222386\n",
      "Iter 199  ll = -44900.222033\n",
      "Iter 200  ll = -44900.221676\n",
      "Pollution bucket prediction accuracy: 0.502\n"
     ]
    }
   ],
   "source": [
    "cols_we_keep = [\n",
    "    'Nitrogen (% dw)_binned',\n",
    "    'Sulfur (% dw)_binned',\n",
    "    'Phosphorous (ppm dw)_binned',\n",
    "    'Lead (ppm dw)_binned',\n",
    "    'Copper (ppm dw)_binned',\n",
    "    'Chromium (ppm dw)_binned',\n",
    "    'Year of tissue collection_binned',\n",
    "    'Air pollution score_binned',\n",
    "    'Region_binned',\n",
    "    'Code for scientific name and authority in lookup table_binned'\n",
    "]\n",
    "df_clean = df[cols_we_keep].dropna().reset_index(drop=True)\n",
    "\n",
    "train_df, test_df = train_test_split(df_clean, test_size=0.2, random_state=42)\n",
    "# train em\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "model = BayesianNetworkEM(train_df,hidden_states=2, seed=0) \n",
    "\n",
    "model.run(max_iters=200, tol=1e-6)\n",
    "\n",
    "# eval on test set\n",
    "true_test_labels = test_df['Air pollution score_binned'].values\n",
    "poll_mapping = model.maps[model.pollution_col]\n",
    "predicted_labels = []\n",
    "\n",
    "for _, row in test_df.iterrows():\n",
    "    probs = model.predict_pollution_from_elem_species(row)\n",
    "    # Pick most likely bucket\n",
    "    pred_idx = np.argmax(probs)\n",
    "    pred_label = model.rev[model.pollution_col][pred_idx]\n",
    "    predicted_labels.append(pred_label)\n",
    "\n",
    "predicted_labels = np.array(predicted_labels)\n",
    "\n",
    "# accuracy score\n",
    "accuracy = np.mean(predicted_labels == true_test_labels)\n",
    "print(f\"Pollution bucket prediction accuracy: {accuracy:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "4991aae2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " P(Region) \n",
      "10: 0.0446\n",
      "6: 0.9554\n",
      "\n",
      " P(Year) \n",
      "before 1995: 0.2201\n",
      "1995-2005: 0.6141\n",
      "2005-present: 0.1658\n",
      "\n",
      " CPT: P(H | Region, Year)\n",
      "Region=10                    Year=before 1995           ->  H=0: 0.9998  H=1: 0.0002\n",
      "Region=10                    Year=1995-2005             ->  H=0: 0.9995  H=1: 0.0005\n",
      "Region=10                    Year=2005-present          ->  H=0: 0.9809  H=1: 0.0191\n",
      "Region=6                     Year=before 1995           ->  H=0: 0.2061  H=1: 0.7939\n",
      "Region=6                     Year=1995-2005             ->  H=0: 0.1377  H=1: 0.8623\n",
      "Region=6                     Year=2005-present          ->  H=0: 0.1095  H=1: 0.8905\n",
      "\n",
      " CPT: P(Pollution | H) \n",
      "H=0  Pollution=low                        ->  0.8047\n",
      "H=0  Pollution=medium                     ->  0.1276\n",
      "H=0  Pollution=high                       ->  0.0677\n",
      "\n",
      "H=1  Pollution=low                        ->  0.2222\n",
      "H=1  Pollution=medium                     ->  0.3884\n",
      "H=1  Pollution=high                       ->  0.3894\n",
      "\n",
      "\n",
      " CPT: P(Species | H, Pollution) \n",
      "H=0  Pollution=low                        ->  Other: 0.1881  Species 1: 0.6646  Species 3: 0.0000  Species 4: 0.0000  Species 5: 0.1472\n",
      "H=0  Pollution=medium                     ->  Other: 0.2861  Species 1: 0.4463  Species 3: 0.0003  Species 4: 0.0002  Species 5: 0.2671\n",
      "H=0  Pollution=high                       ->  Other: 0.1300  Species 1: 0.4608  Species 3: 0.0005  Species 4: 0.0005  Species 5: 0.4082\n",
      "\n",
      "H=1  Pollution=low                        ->  Other: 0.3749  Species 1: 0.0008  Species 3: 0.0433  Species 4: 0.2867  Species 5: 0.2942\n",
      "H=1  Pollution=medium                     ->  Other: 0.2578  Species 1: 0.2612  Species 3: 0.0853  Species 4: 0.1030  Species 5: 0.2928\n",
      "H=1  Pollution=high                       ->  Other: 0.3875  Species 1: 0.0894  Species 3: 0.1225  Species 4: 0.1499  Species 5: 0.2507\n",
      "\n",
      "\n",
      " CPT: P(Nitrogen (% dw)_binned | Pollution, Species) \n",
      "Pollution=low                        Species=Other                      ->  low: 0.1688  medium: 0.2704  high: 0.5608\n",
      "Pollution=low                        Species=Species 1                  ->  low: 0.8021  medium: 0.1821  high: 0.0158\n",
      "Pollution=low                        Species=Species 3                  ->  low: 0.0668  medium: 0.7331  high: 0.2001\n",
      "Pollution=low                        Species=Species 4                  ->  low: 0.1040  medium: 0.4899  high: 0.4060\n",
      "Pollution=low                        Species=Species 5                  ->  low: 0.5208  medium: 0.4560  high: 0.0232\n",
      "\n",
      "Pollution=medium                     Species=Other                      ->  low: 0.2189  medium: 0.3116  high: 0.4694\n",
      "Pollution=medium                     Species=Species 1                  ->  low: 0.6972  medium: 0.2766  high: 0.0262\n",
      "Pollution=medium                     Species=Species 3                  ->  low: 0.1355  medium: 0.6774  high: 0.1871\n",
      "Pollution=medium                     Species=Species 4                  ->  low: 0.1123  medium: 0.4973  high: 0.3904\n",
      "Pollution=medium                     Species=Species 5                  ->  low: 0.5299  medium: 0.4384  high: 0.0317\n",
      "\n",
      "Pollution=high                       Species=Other                      ->  low: 0.0867  medium: 0.1706  high: 0.7426\n",
      "Pollution=high                       Species=Species 1                  ->  low: 0.5255  medium: 0.3979  high: 0.0766\n",
      "Pollution=high                       Species=Species 3                  ->  low: 0.1166  medium: 0.3049  high: 0.5784\n",
      "Pollution=high                       Species=Species 4                  ->  low: 0.0074  medium: 0.2711  high: 0.7216\n",
      "Pollution=high                       Species=Species 5                  ->  low: 0.1975  medium: 0.4053  high: 0.3971\n",
      "\n",
      "\n",
      " CPT: P(Sulfur (% dw)_binned | Pollution, Species) \n",
      "Pollution=low                        Species=Other                      ->  low: 0.1652  medium: 0.3702  high: 0.4646\n",
      "Pollution=low                        Species=Species 1                  ->  low: 0.7968  medium: 0.1226  high: 0.0806\n",
      "Pollution=low                        Species=Species 3                  ->  low: 0.1335  medium: 0.5332  high: 0.3333\n",
      "Pollution=low                        Species=Species 4                  ->  low: 0.2383  medium: 0.6141  high: 0.1477\n",
      "Pollution=low                        Species=Species 5                  ->  low: 0.4676  medium: 0.4213  high: 0.1111\n",
      "\n",
      "Pollution=medium                     Species=Other                      ->  low: 0.2150  medium: 0.3925  high: 0.3925\n",
      "Pollution=medium                     Species=Species 1                  ->  low: 0.7383  medium: 0.1290  high: 0.1327\n",
      "Pollution=medium                     Species=Species 3                  ->  low: 0.1033  medium: 0.5483  high: 0.3484\n",
      "Pollution=medium                     Species=Species 4                  ->  low: 0.2514  medium: 0.5508  high: 0.1979\n",
      "Pollution=medium                     Species=Species 5                  ->  low: 0.3979  medium: 0.4577  high: 0.1444\n",
      "\n",
      "Pollution=high                       Species=Other                      ->  low: 0.0825  medium: 0.2797  high: 0.6377\n",
      "Pollution=high                       Species=Species 1                  ->  low: 0.6887  medium: 0.2143  high: 0.0970\n",
      "Pollution=high                       Species=Species 3                  ->  low: 0.0538  medium: 0.2736  high: 0.6726\n",
      "Pollution=high                       Species=Species 4                  ->  low: 0.1209  medium: 0.4872  high: 0.3919\n",
      "Pollution=high                       Species=Species 5                  ->  low: 0.1194  medium: 0.3457  high: 0.5350\n",
      "\n",
      "\n",
      " CPT: P(Phosphorous (ppm dw)_binned | Pollution, Species) \n",
      "Pollution=low                        Species=Other                      ->  low: 0.2196  medium: 0.3122  high: 0.4682\n",
      "Pollution=low                        Species=Species 1                  ->  low: 0.8021  medium: 0.1751  high: 0.0228\n",
      "Pollution=low                        Species=Species 3                  ->  low: 0.0224  medium: 0.2223  high: 0.7553\n",
      "Pollution=low                        Species=Species 4                  ->  low: 0.6409  medium: 0.2987  high: 0.0604\n",
      "Pollution=low                        Species=Species 5                  ->  low: 0.2384  medium: 0.6111  high: 0.1505\n",
      "\n",
      "Pollution=medium                     Species=Other                      ->  low: 0.1519  medium: 0.2189  high: 0.6292\n",
      "Pollution=medium                     Species=Species 1                  ->  low: 0.7140  medium: 0.2299  high: 0.0561\n",
      "Pollution=medium                     Species=Species 3                  ->  low: 0.0452  medium: 0.4516  high: 0.5032\n",
      "Pollution=medium                     Species=Species 4                  ->  low: 0.4492  medium: 0.3369  high: 0.2139\n",
      "Pollution=medium                     Species=Species 5                  ->  low: 0.2711  medium: 0.5616  high: 0.1673\n",
      "\n",
      "Pollution=high                       Species=Other                      ->  low: 0.0867  medium: 0.2532  high: 0.6601\n",
      "Pollution=high                       Species=Species 1                  ->  low: 0.5306  medium: 0.3316  high: 0.1378\n",
      "Pollution=high                       Species=Species 3                  ->  low: 0.0359  medium: 0.3049  high: 0.6591\n",
      "Pollution=high                       Species=Species 4                  ->  low: 0.3553  medium: 0.3700  high: 0.2747\n",
      "Pollution=high                       Species=Species 5                  ->  low: 0.1687  medium: 0.3868  high: 0.4444\n",
      "\n",
      "\n",
      " CPT: P(Lead (ppm dw)_binned | Pollution, Species) \n",
      "Pollution=low                        Species=Other                      ->  low: 0.5372  medium: 0.3376  high: 0.1252\n",
      "Pollution=low                        Species=Species 1                  ->  low: 0.5937  medium: 0.3082  high: 0.0981\n",
      "Pollution=low                        Species=Species 3                  ->  low: 0.1335  medium: 0.2001  high: 0.6664\n",
      "Pollution=low                        Species=Species 4                  ->  low: 0.5033  medium: 0.3490  high: 0.1477\n",
      "Pollution=low                        Species=Species 5                  ->  low: 0.1783  medium: 0.3542  high: 0.4676\n",
      "\n",
      "Pollution=medium                     Species=Other                      ->  low: 0.4142  medium: 0.2505  high: 0.3353\n",
      "Pollution=medium                     Species=Species 1                  ->  low: 0.4561  medium: 0.4037  high: 0.1402\n",
      "Pollution=medium                     Species=Species 3                  ->  low: 0.0581  medium: 0.1678  high: 0.7741\n",
      "Pollution=medium                     Species=Species 4                  ->  low: 0.4278  medium: 0.4064  high: 0.1658\n",
      "Pollution=medium                     Species=Species 5                  ->  low: 0.1004  medium: 0.3856  high: 0.5141\n",
      "\n",
      "Pollution=high                       Species=Other                      ->  low: 0.2685  medium: 0.2573  high: 0.4741\n",
      "Pollution=high                       Species=Species 1                  ->  low: 0.5204  medium: 0.4031  high: 0.0766\n",
      "Pollution=high                       Species=Species 3                  ->  low: 0.0180  medium: 0.2287  high: 0.7533\n",
      "Pollution=high                       Species=Species 4                  ->  low: 0.3809  medium: 0.4029  high: 0.2161\n",
      "Pollution=high                       Species=Species 5                  ->  low: 0.1173  medium: 0.3519  high: 0.5309\n",
      "\n",
      "\n",
      " CPT: P(Copper (ppm dw)_binned | Pollution, Species) \n",
      "Pollution=low                        Species=Other                      ->  low: 0.2577  medium: 0.4338  high: 0.3085\n",
      "Pollution=low                        Species=Species 1                  ->  low: 0.7723  medium: 0.1209  high: 0.1068\n",
      "Pollution=low                        Species=Species 3                  ->  low: 0.0002  medium: 0.5110  high: 0.4888\n",
      "Pollution=low                        Species=Species 4                  ->  low: 0.6745  medium: 0.1611  high: 0.1644\n",
      "Pollution=low                        Species=Species 5                  ->  low: 0.1736  medium: 0.5347  high: 0.2917\n",
      "\n",
      "Pollution=medium                     Species=Other                      ->  low: 0.1834  medium: 0.3629  high: 0.4536\n",
      "Pollution=medium                     Species=Species 1                  ->  low: 0.7289  medium: 0.1664  high: 0.1047\n",
      "Pollution=medium                     Species=Species 3                  ->  low: 0.0001  medium: 0.4258  high: 0.5741\n",
      "Pollution=medium                     Species=Species 4                  ->  low: 0.6951  medium: 0.1498  high: 0.1551\n",
      "Pollution=medium                     Species=Species 5                  ->  low: 0.1056  medium: 0.5387  high: 0.3556\n",
      "\n",
      "Pollution=high                       Species=Other                      ->  low: 0.0825  medium: 0.3580  high: 0.5594\n",
      "Pollution=high                       Species=Species 1                  ->  low: 0.6887  medium: 0.1582  high: 0.1531\n",
      "Pollution=high                       Species=Species 3                  ->  low: 0.0135  medium: 0.2556  high: 0.7309\n",
      "Pollution=high                       Species=Species 4                  ->  low: 0.5604  medium: 0.3150  high: 0.1246\n",
      "Pollution=high                       Species=Species 5                  ->  low: 0.0679  medium: 0.4671  high: 0.4650\n",
      "\n",
      "\n",
      " CPT: P(Chromium (ppm dw)_binned | Pollution, Species) \n",
      "Pollution=low                        Species=Other                      ->  low: 0.3938  medium: 0.3448  high: 0.2613\n",
      "Pollution=low                        Species=Species 1                  ->  low: 0.8826  medium: 0.0841  high: 0.0333\n",
      "Pollution=low                        Species=Species 3                  ->  low: 0.1335  medium: 0.5110  high: 0.3555\n",
      "Pollution=low                        Species=Species 4                  ->  low: 0.4329  medium: 0.4933  high: 0.0739\n",
      "Pollution=low                        Species=Species 5                  ->  low: 0.1134  medium: 0.4514  high: 0.4352\n",
      "\n",
      "Pollution=medium                     Species=Other                      ->  low: 0.2229  medium: 0.4280  high: 0.3491\n",
      "Pollution=medium                     Species=Species 1                  ->  low: 0.8654  medium: 0.1047  high: 0.0299\n",
      "Pollution=medium                     Species=Species 3                  ->  low: 0.0452  medium: 0.5096  high: 0.4451\n",
      "Pollution=medium                     Species=Species 4                  ->  low: 0.4813  medium: 0.4492  high: 0.0696\n",
      "Pollution=medium                     Species=Species 5                  ->  low: 0.0370  medium: 0.4419  high: 0.5211\n",
      "\n",
      "Pollution=high                       Species=Other                      ->  low: 0.1091  medium: 0.3203  high: 0.5706\n",
      "Pollution=high                       Species=Species 1                  ->  low: 0.7805  medium: 0.1633  high: 0.0562\n",
      "Pollution=high                       Species=Species 3                  ->  low: 0.0314  medium: 0.2780  high: 0.6905\n",
      "Pollution=high                       Species=Species 4                  ->  low: 0.3040  medium: 0.4542  high: 0.2418\n",
      "Pollution=high                       Species=Species 5                  ->  low: 0.0453  medium: 0.2860  high: 0.6687\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.print_CPTs(precision=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
